I"<p>If you have ever watched a film set in the future, then you know of AI superintelligence (#iykyk). In these films, the computers are capable of the unfathomable and even the unreasonable.</p>

<!--more-->

<p>Currently, our AI algorithms possess narrow intelligence, meaning that they are smarter than human in only specific fields. For example, they may be better at evaluating math expressions and beating humans in chess, but they lack the judgement and decision-making of humans. The next step is general intelligence, where machines are on par with humans and can act as doctors, lawyers, programmers, and other meaningful jobs. The step after is superintelligence, the most interesting and consequential of the three. With superintelligence, computers would take over as the dominant species on this planet; they would be able to think and operate like humans but on a much higher level.</p>

<p>Obviously, life will become a lot easier if superintelligence is reached. Some of the biggest problems in the world like inequality and climate change may be solved by these supergenius machines. The sciences may be explored and conquered, the inefficiencies of governments and politics resolved, the deficiencies of healthcare removed.</p>

<p>However it is also important to consider the drawbacks of this technology ‚Äì of which there are many. We face threats of job loss due to automation, biases from algorithms reinforcing inequalities in society, concentration of power in the hands of those who control the technology, and other ethical issues involving computers behave like humans. With intelligence comes power, and with power comes responsibility.</p>

<p>The term, ‚Äúsingularity‚Äù, dubbed by researcher Vernon Vinge refers to the ‚Äúpoint in time when ASI will abruptly trigger runaway technological growth, resulting in unfathomable changes to human civilization‚Äù, giving the appearance of reaching some ‚Äúsingularity‚Äù. Still, there are many challenges to conquer before even general artificial intelligence is reached. Some of the things that come the easiest for humans are inherently hardest for computers to learn, like vision, motion, movement, and perception.</p>

<p>Its especially interesting to think about how soon this change could be coming though. Technological progress is not linear, but rather exponential, so all of this could be happening in a blink of an eye. 1000 years ago, algebra was invented. 300 years ago, there was no electricity. 50 years ago, there was no internet. This is why the questions/concerns over ASI should be answered now, instead of the future where it will be already be too late.</p>

<p>To me, the biggest question to answer is how we can achieve safe(well-regulated and transparent) technological progress without inhibiting it. I argue that we have too much of an emphasis on creation, which results in technology that is created for the sake of creation and pushed onto consumers to ‚Äúbetter‚Äù their lives. More is not necessarily better. Instead, we need technologists to bring their understanding to the institutions and communities that rely on their creations. Then, we can truly ensure that we are in control of our creations and that they are leading us down the right path. There are so many cs majors in every university, yet most of them turn to software engineering after graduation. As writer, Tyler Bettilyon, puts it, ‚ÄúExperienced technologists need to rethink their next venture. Don‚Äôt start a law tech company, start a technology focused law firm. Don‚Äôt run the technology department for a political campaign, run a political campaign centered on technology. Don‚Äôt create technology for educators, educate people about technology.‚Äù This would go a long way in producing safe, innovative technology and prepare us better for a future of artificial superintelligence.</p>
:ET